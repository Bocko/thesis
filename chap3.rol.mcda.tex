\Chapter{Review of the literature}{Part II: Operations research}
\label{cha:rol2.mcda}

\begin{summary}
\lipsum[1]
\end{summary}

\section{Introduction}
\label{sec:rol2.intro}
In this chapter, we briefly present the major tools from the operations research, in particular the multi-objective optimization and the multi-criteria decision aid, in order to justify our choice to use such a paradigm. As stated in Chapter \ref{cha:rol.icdesign}, the 3D integration can offer new perspectives but designing 3D-SICs includes two major distinctive features: multiple criteria and a huge number of possible solutions. When facing such problems, two main methods exist: the uni-criterion paradigm and the multi-criteria paradigm. For optimization problems, these paradigm will refer to the terminology mono-objective/multi-objective optimization while for decision aid, the terminology uni-criterion/multi-criteria will be used.

In the following, we will briefly describe each paradigm, showing some of the main approaches alongside illustrative examples. We will first present the uni-criterion methodology, show why it can be limited and explain how a multi-criteria paradigm can be more suitable.

\section{The uni-criterion paradigm}
\label{sec:rol2.unicrit_paradigm}

\subsection{Problem formulation}
An optimization problem can be formulated, without loss of generality, as \cite{BraMar2002}
\begin{equation}
\label{eqn:optiprob}
\begin{gathered}
\min f(x)\\
x \in A
\end{gathered}
\end{equation}
where $f$ is a real-valued function evaluating the solutions denoted $x$, $f$ is also called the \emph{criterion} on which $x$ is evaluated. Let us note that the equation \ref{eqn:optiprob} expresses a \emph{minimization} problem. A \emph{maximization} problem can be seen as a minimization problem with the identity
$$
\max_{x \in A} f(x) = - \min_{x \in A} (-f(x))
$$
so that there is no loss of generality by using only \emph{minimization} formulation.

In order to give a more precise idea of what an optimization problem is, we will describe in the next section some typical examples taken from the reference book \cite{talbi09, BraMar2002}.

\subsection{Examples of typical optimization problems}
\subsubsection{Linear programming}
Linear programming (LP) is a method that aims to optimize a linear function, subject to linear equality and linear inequality constraints. This can be formulated as follows:
\begin{equation}
\min \mathbf{c}^\intercal\mathbf{x}
\end{equation}
subject to
\begin{equation*}
\begin{gathered}
A\mathbf{x} \leq \mathbf{b}\\
\mathbf{x} \geq \mathbf{0}
\end{gathered}
\end{equation*}
where $\mathbf{x}$ is a vector of continuous variables to be determined, $\mathbf{c}$ and $\mathbf{b}$ are vectors of coefficients, $A$ is a matrix of coefficients.

Efficient exact methods for solving LP problem exist such as, among the most knowns, the simplex algorithm \cite{dantzig51} or the interior point method \cite{Karmarkar84}.

\begin{example}[Linear programming]
A given company produces two electronic boards $Board_1$ and $Board_2$ based on two kinds of memories $M_1$ and $M_2$. The objective consists in finding the most profitable product mix, given the availability of each memory $M_1$ and $M_2$, and for each board $Board_i$ the used amount of memories and the profit. 
\end{example}

\subsubsection{Integer linear programming}
Integer linear programming deals with linear problems where the variables are restricted to be integers:
\begin{equation}
\min \mathbf{c}^\intercal\mathbf{x}
\end{equation}
subject to
\begin{equation*}
\begin{gathered}
A\mathbf{x} \leq \mathbf{b}\\
\mathbf{x} \geq \mathbf{0}\\
\mathbf{x} \in \mathbb{Z}
\end{gathered}
\end{equation*}
where $\mathbf{c}$ and $\mathbf{b}$ are vectors having integers values and $A$ is a matrix of coefficients having integer values.

When the decision variables are both discrete en continuous, the problem refers to \textbf{mixed integer programming} (MILP).

Other particular ILP problems which deals with variables that are restricted to be either 0 or 1 are called \textbf{0-1 linear programming}.

\begin{example}[Travelling salesman problem (TSP)]
This is one of the most known optimization problem. It can be formulated as follows: given $n$ cities and the distance between each pair of cities, we have to find the shortest tour that visits each city once and returns to the origin city. This problem can be formulated as an ILP problem.
\end{example}

\subsubsection{Non-linear programming}
Non-linear programming (NLP) models deal with mathematical problems where some of the constraints and/or the objective function are non linear:
\begin{equation}
\min \mathbf{c}^\intercal\mathbf{x}
\end{equation}
where
\begin{equation*}
\begin{gathered}
f: \mathbb{R}^n \rightarrow \mathbb{R}\\
x \in \mathbb{R}^n
\end{gathered}
\end{equation*}
subject to
\begin{equation*}
\begin{gathered}
g_i(x) \leq 0, i \in J = 1, \dots, m\\
h_j(x) = 0, j \in I = 1, \dots, p
\end{gathered}
\end{equation*}
where $g_i : X \rightarrow \mathbb{R}^n$ are the inequality constraints and $h_j : X \rightarrow \mathbb{R}^n$ are the equality constraints.

NLP are generally more difficult to solve than LP \cite{talbi09} and metaheuristics (see Section \ref{subsec:metaheuristics}) are commonly used to solve this class of problems.
%\subsubsection{Dynamic programming}


%\subsubsection{Assignment problem}


\section{From the uni-criterion paradigm to the multi-criteria paradigm}
\label{sec:rol2.unicritmulticrit}

With a uni-criterion paradigm, the optimization of one criterion is generally performed while considering that this single criterion synthesizes all the parameters of the problems or that the other criteria already satisfy an acceptable level. This methodology will try to give a solution which is supposed to be optimal according to this criterion and unique. However, most problems encountered in the field of IC design, and more generally in other industrial fields, contains several conflicting criteria as it will be illustrated in Section \ref{}. Finding a solution that simultaneously optimizes all the criteria is only possible in rare cases and if optimality can be reached, there may be cases where several solutions share the same evaluations on all the criteria.

For instance, when designing ICs, a manufacturer will try to simultaneously maximize the performance while minimize the cost of the circuit. However, we can already guess that those two objectives are conflicting. Also, producing high-end ICs can be subject to more difficulties in terms of thermal dissipation. In addition, a criterion based on ecological standards may have impacts on the cost and the performance of an IC.

This example shows that a uni-criterion approach cannot always be applied since there is no achievable optimum. A solution that optimizes one criterion will likely to affect another.

In order to deal with the multiple criteria of a problem, another paradigm consists in taking into account all the criteria simultaneously. This is the aim of the multi-criteria paradigm which aim to:
\begin{enumerate}
\item find the solutions that optimizes all the criteria simultaneously with the multi-objective optimization;
\item provide support to a decision maker facing several conflicting solutions with multi-criteria decision aid (MCDA) that allows to highlight such conflicts and therefore obtain a compromise with a transparent process.
\end{enumerate}

\section{The multi-criteria paradigm}
\label{sec:rol2.multicrit_paradigm}

% In order to deal with the multiple objectives of a problem, another approach consists in taking into account all the criteria simultaneously. This is the aim of multi-criteria decision aid which goal is to provide support to a decision maker facing several conflicting solutions. MCDA allows to highlight such conflicts and therefore obtain a compromise with a transparent process.

\subsection{Problem formulation}
A multi-criteria problem can be formulated without loss of generality as follows \cite{BraMar2002}:
\begin{equation}
\label{multicrit_formulation}
\begin{gathered}
\min \{f_1(x), f_2(x), \dots, f_m(x)\}\\
x \in A
\end{gathered}
\end{equation}
where $\{f_1(x), f_2(x), \dots, f_m(x)\}$ is a set denoted $\mathcal{F}$ of $m$ evaluation criteria that needs to be minimized and $x$ is a solution of the set $\mathcal{A} = \{a_1, a_2, \dots, a_n\}$.

As explained in Section \ref{sec:rol2.unicritmulticrit}, an optimal solution can be impossible to find for a multi-criteria problem. However, compromise solutions exists and in order to identify them, a dominance relation has been defined \cite{BraMar2002}:

\begin{definition}[Dominance]
A solution $a_1$ dominates a solution $a_2$ if:
\begin{itemize}
\item $a_1$ is as least as good as $a_2$ on all criteria;
\item $a_1$ is strictly better than $a_2$ on at least one criterion.
\end{itemize}
\end{definition}

From this dominance relation, it is then possible to filter the solutions in order to keep only the non-dominated ones. This set of \emph{efficient} solutions is called the Pareto frontier and the solutions that belong to this set are incomparable.

Two approaches can be used to establish this set~\cite{Vin92}:
\begin{itemize}
\item \textit{Exact methods} which aims to compute the Pareto frontier directly~\cite{EhrgottGandibleuxbook02,steuer86a}.
\item \textit{Approximate methods} which are based on metaheuristics to quickly explore the solution space and approach as best as possible the Pareto optimal frontier\cite{talbi09}.
\end{itemize}
As explained in Section \ref{}, designing 3D-SICs includes a huge solution space to deal with in the optimization process. The solution (that is to say the most-suitable 3D-SIC architecture) is unknown and an exhaustive search would take a prohibitive time. Also, due to the nature of the criteria (discrete and continuous variables, linear and non-linear criteria) that will be defined in Section \ref{}, we have few hopes to be able to develop an exact method. For those reasons, approximate methods with metaheuristics for multi-objective optimization will be used. Let us also remind that the aim of this thesis is to show the applicability of a multi-criteria paradigm to the design of 3D circuits.

\subsection{Metaheuristics for multi-objective optimization}
\label{subsec:metaheuristics}
Metaheuristics are a family of approximate optimization methods. They aim to provide "acceptable" solutions in reasonable time for solving complex problems \cite{talbi09}. As stated previously, the optimal solution of a multi-objective optimization problem (MOP) is not a single solution as for mono-objective optimization problem, but a set of solutions defined as Pareto optimal solutions. The main goal is therefore to obtain these compromise solutions.

In our study, there are few hopes to find the exact Pareto optimal solutions. In such cases, metaheuristics are commonly used and the goal is then to find an approximation of this set. Two properties has to be respected in order to ensure good approximations: convergence to the Pareto optimal front and uniform diversity. The first property allows to have solutions that are closed to the Pareto set whereas the second property shows a good distribution around the Pareto front.

Numerous metaheuristics have been developed since the 50s. Among the most known, let us cite genetic algorithm \cite{holland1975adaptation}, scatter search \cite{Glover77}, simulated annealing \cite{KirkpatrickGelattVecchi83}, tabu search \cite{Glover86}, memetic algorithms \cite{moscato89on} and ant colony optimization \cite{Dor92a.phd}.

In this work, we will focus on genetic algorithms (GA) as they are quick to implement for a first approach and are suitable to heterogeneous variables problems. More details about other metaheuristics can be found in reference books such as \cite{talbi09,dreo06metaheuristics,8125462}.

\subsection{Genetic algorithm}
Genetic algorithm has been developed by Holland in the 1970s \cite{holland1975adaptation}. It is a metaheuristic that reproduces the properties of natural selection as described by Charles Darwin. GA is based on the principle of the improvement of the gene pool of a population over generations. GAs will mimics the natural evolution with techniques such as selection, crossover and mutation.

The methodology rely on a population that is evolved toward better solutions or individuals. The evolution is an iterative process and starts usually with a randomly-generated solutions. At each iteration, every individual is evaluated to define its fitness. The fitter ones are more likely to be selected for genetic modifications (crossover and possibly mutation). The produced solutions constitutes the new generation that will be used for the next iteration. The algorithm is commonly terminated when a maximum number of generations has been produced or when a certain fitness level has been satisfied.

\subsubsection{Representation of a solution}
The representation or encoding of a solution is called a chromosome and depends on the problem. Several examples of problems show binary encodings however, in our study we will use a real-valued matrix that will be detailed in Section \ref{}. Nevertheless, without loss of generality, we will illustrate the principles of a genetic algorithm by using binary-coded solutions.

\subsubsection{Initialization}
Initially many solutions are generated, usually randomly to form the initial population. The number of produced individuals range from hundreds to thousands. Depending on the problem, the generation of the initial population can be guided (seeded) to areas where optimal solutions are likely to be found.

\subsubsection{Selection}
The selection is a stochastic process usually planned so that the fitter solutions have a higher probability of being selected. This aims to ensure the convergence of the algorithm.

\subsubsection{Crossover}
Once a pair of individuals has been selected, they will be crossed-over. Typically, two children are created from each set of parents. One method of crossover will be explained here but other approaches exists \cite{}. A random crossover point will be selected on both parents. Beyond that point, the data will be swapped with the information of the other parent, as shown in Figure \ref{}.

\subsubsection{Mutation}
Mutation is a genetic operation used to ensure diversity in the generated populations. It changed one or more information in the chromosome of an individual. This alteration depends on how the solution is encoded. If it is a bit string, the most common operation is to apply a bit flip (see Figure \ref{}) while for float chromosomes, new values can be generated following user-defined rules (see detailed illustration in Section \ref{}).

\subsubsection{Termination}
The generational process is repeated until a termination condition has been encountered. Common conditions are:
\begin{itemize}
\item a certain level of fitness reached;
\item fixed number of generations reached;
\item simulation elapsed time reached;
\item no better results produced after several generations.
\end{itemize}

\subsection{Multi-objective genetic algorithm: NSGA-II}
\cite{Srinivas94multiobjectiveoptimization, Deb00afast}

\subsection{Multi-criteria decision aid}
\label{subsec:mcda}
Once the Pareto frontier is obtained or approximated, the compromise solutions can be found by establishing a preference model of the decision maker facing several conflicting solutions. Those models can be classified into three broad categories \cite{Vin92, beltstew} whose methods will be detailed in Section \ref{subsec:mcdamethods}:

\begin{enumerate}
\item \textit{Aggregation methods}: numerical scores are calculated in relationship with the criteria to determine the level of preference for a solution. The most known aggregation methods are the Multi-Attribute Utility Theory (MAUT) \cite{MMAUT} and the Analytic Hierarchy Process \cite{MAHP}.
\item \textit{Interactive methods}: it is a sequential process composed by alternating computation steps and dialogue with the decision maker. A first compromise is submitted to the decision maker who can accept or deny it. If the solution is denied, the DM can give extra information about his preferences (dialogue) and a new solution can be calculated, so a new decision process begins. Otherwise, no better solution can be found and the process stops. Among the most known interactive methods, the STEP Method (STEM) \cite{benayoun71} or the Satisficing Trade-Off Method (STOM) \cite{nakayama84} can be cited.
\item \textit{Outranking methods}: the solutions are compared pairwise, initially for each criterion, which enables the possibility to identify the relationship between the solutions. This shows the preference for a solution in comparison to another one. PROMETHEE \cite{Brans1} and ELECTRE \cite{Roy66} are among the most known outranking methods.
\end{enumerate}

%Those methods will not be described further here, as they can be found in reference books such as \cite{Vin92}, \cite{BraMar2002, EhrgottFigueiraGreco2005, beltstew, Sch85}.

Generally, the purpose of MCDA is to give answers for three main problematics \cite{EhrgottFigueiraGreco2005}:
\begin{enumerate}
\item \textit{The choice problematic (P.$\alpha$)}: the aid aims the selection of a small number of good solutions in such way that one or several solutions can be chosen.
\item \textit{The sorting problematic (P.$\beta$)}: the aid aims the assignment of each solution to a predefined ordered category.
\item \textit{The ranking problematic (P.$\gamma$)}: the aid aims the complete or partial preorder of all the solutions.
\end{enumerate}

\subsection{Some important multi-criteria methods}
\label{subsec:mcdamethods}

\subsubsection{Multi-Attribute Utility Theory}
Multi-Attribute Utility Theory (MAUT) has been introduced by Fishburn \cite{Fishburn70} and Keeney and Raiffa \cite{KeeneyRaiffa76}. This method belongs to the family of aggregation methods that consist in substituting the initial multi-criteria problem
\begin{equation}
\min \{f_1(x), f_2(x), \dots, f_m(x) | x \in \mathcal{A}\}
\end{equation}
the following uni-criterion problem:
\begin{equation}
min \{U(x) | x \in \mathcal{A}\}
\end{equation}
where $U(x)$ is called the utility function that aggregates all the criteria to a single criterion:
\begin{equation}
U(x) = U[f_1(x), f_2(x), \dots, f_m(x)]
\end{equation}

One of the most used utility function is the weighted sum:
\begin{equation}
U(x) = \sum_{j=1}^{m} w_j f_j(x)
\end{equation}


\subsubsection{Analytical Hierarchy Process (AHP)}
Analytical Hierarchy Process (AHP) has been developed by Saaty \cite{MAHP}. This multi-criteria method is based on mathematics and psychology and allows to face structurally complex choices by decomposing the problem in several sub-problems that can be analysed independently and are easier to understand. Similarly to PROMETHEE and ELECTRE, AHP also proceeds by making pairwise comparisons of the alternatives, but on basis of eigenvectors. Indeed, one of the distinctive features of this methods is to build a matrix by asking the decision maker to compare all pairs of alternatives and criteria. The normalized right-hand eigenvector of this matrix is then used to compute the score associated to each alternative and the weight associated to each criterion. This methods can be summarized in seven key steps \cite{Vaidya20061}

\begin{enumerate}
\item State the problem
\item Broaden the objectives of the problem or consider all actors, objectives and its outcome.
\item Identify the criteria that influence the behaviour.
\item Structure the problem in a hierarchy of different levels constituting goal, criteria, sub-criteria and alternatives.
\item Compare each element in the corresponding level and calibrate them on the numerical scale. Consequently build the comparison matrix with the computed valued based on the comparisons.
\item Compute the highest eigenvalue of the matrix, the consistecy index (CI), the consistency ration (CR) and the normalized values for each criterion/alternative.
\item If the maximum eigenvalue, CI and CR are satisfactory, the decision is taken based on the normalized values. Otherwise, the procedure is repeated until these values reach an acceptable range.
\end{enumerate}

\subsubsection{STEP Method (STEM)}
The STEP Method has been proposed by Benayoun \cite{benayoun71}. STEM is an interactive and iterative exploration procedure that aims to reach the best compromise according the decision maker after a certain number of cycles. Each cycle is composed of a calculation phase and a decision-making phase (discussion with the decision maker):
\begin{enumerate}
\item An efficient compromise solution is determined.
\item This solution is submitted to the decision maker. Three cases can then happen:
	\begin{enumerate}
	\item \label{stem2} The decision maker is satisfied and the procedure ends;
	\item The decision maker wants to simultaneously improve all the evaluations. This is impossible since the proposed solution is efficient. The procedure ends and cannot help the decision maker.
	\item The decision maker identifies a particular criterion on which a concession can be made in order to improve other criteria. A new efficient solution can then be determined.
	\item This new solution is submitted. Go to step \ref{stem2}.
	\end{enumerate}
\end{enumerate}

\subsubsection{Satisficing Trade-Off Method (STOM)}
The STOM method has been proposed by Nakayama \cite{nakayama84}. Similarly to STEM, it relies on a discussion with the decision maker but is based on the setting of an ideal defined as follows:
\begin{definition}[Ideal point]
The ideal point $f^*=(f_1^*, f_2^*, \dots, f_m^*)$ is defined such that $f_i^* = \min \{f_i(x), \forall i=1, 2, \dots, m, \forall x \in \mathcal{A}\}$. The ideal point possesses as coordinates the best values that can be achieved for each criterion separately.
\end{definition}
STOM can be summarized in four steps:
\begin{enumerate}
\item The first step is to set the ideal point.
\item Then the aspiration level for each criterion is asked to the decision maker.
\item \label{stom3} A Pareto solution nearest to the aspiration level is determined.
\item This solution is submitted to the decision maker. If it is satisfactory, the procedure ends. Otherwise, the decision maker is asked to trade off to define another aspiration level. Go to step \ref{stom3}.
\end{enumerate}

\subsubsection{The PROMETHEE methods}
PROMETHEE (Preference Ranking Organisation METHod for Enrichment Evaluations) has been initiated by Brans \cite{Brans1}. In this section, we will only describe the basics of PROMETHEE. More details can be found in \cite{Beh2010}.\\
The PROMETHEE methods are based on the three following steps:
\begin{itemize}
\item Enriching the preference structure: a preference function is introduced.
\item Enriching the dominance relation: a valued outranking relation is determined.
\item Decision aid: the valued outranking relation are exploited.
\end{itemize}

\begin{enumerate}
\item \textit{\underline{Preference function}}\\
Since the dominance relation is really poor (binary relation), a preference function $P_k(a_1,a_2)$ will be introduce to enrich it. This function gives the preference degree of an alternative $a_1$ over an alternative $a_2$ with respect to the function $d_k(a_1,a_2) = f_k(a_1) - f_k(a_2)$ which is the difference between the evaluation of $a_1$ and $a_2$ for the criterion $j$.\\
Consequently, it is therefore possible several types of preference functions based on preference ($P$) or indifference ($Q$) thresholds. Below the indifference threshold, the decision maker will consider having no preference while above the preference threshold, the decision maker will have no more difference in its preference.

\item \textit{\underline{valued outranking relation}}\\
\textit{Multi-criteria preference index}

The multi-criteria preference index is defined as follows:
\begin{equation}
\pi (a_1, a_2) = \sum_{k=1}^{m} P_{k}(a_1, a_2).w_{k} \text{ with $\sum_{k=1}^{k} w_{k} = 1$}
\end{equation}
where $w_{k}>0, k=1, 2, ..., m$ are the weights on each criterion. $\pi (a_1, a_2)$ represents a measure of the preference of $a_1$ over $a_2$ on all the criteria.

\textit{Outranking flow}

An \og outranking flow \fg is then defined on the basis of the preference index. That allows to compare alternatives with each others. Three types of flow are formulated:
\begin{itemize}
\item The positive outranking flow: $\phi^ {+} = \frac{1}{n-1} \sum_{j \neq i} \pi (a_i, a_j)$. This flow expresses how $a_i$ outranks all the other alternatives.
\item The negative outranking flow:$\phi^ {-} = \frac{1}{n-1} \sum_{j \neq i} \pi (a_j, a_i)$. This flow expresses how $a_i$ is outranked by all the other alternatives.
\item The net flow: $\phi(a) = \phi^{+}(a_i) - \phi^{-}(a_i)$. This flow expresses the balance between the positive and negative flows of $a_i$
\end{itemize}
Based on these flows, the PROMETHEE methods will establish an outranking.

\item \textit{\underline{PROMETHEE I}}

The positive and negative flows allow to sort the alternatives of $A$. Let $(S^{+}, I^{+})$ and $(S^{-}, I^{-})$ be the two complete pre-orders obtained from these flows:
\begin{equation}
\begin{cases}
a_iS^{+}a_j \Leftrightarrow \phi^{+}(a_i) > \phi^{+}(a_j)\\
a_iI^{+}a_j \Leftrightarrow \phi^{+}(a_i) = \phi^{+}(a_j)
\end{cases}
\end{equation}
This means that the higher the positive flow is, the better the alternative.

\begin{equation}
\begin{cases}
a_iS^{-}a_j \Leftrightarrow \phi^{-}(a_i) < \phi^{-}(a_j)\\
a_iI^{-}a_j \Leftrightarrow \phi^{-}(a_i) = \phi^{-}(a_j)
\end{cases}
\end{equation}
This means that the lower the negative flow is, the better the alternative.

PROMETHEE I establishes partial ranking by taking the intersection of these two pre-orders:
\begin{equation}
\begin{cases}
a_iP^{(1)}a_j \Leftrightarrow \begin{cases}
	a_iS^{+}a_j \text{ and } a_iS^{-}a_j\\
	a_iS^{+}a_j \text{ and } a_iI^{-}a_j\\
	a_iI^{+}a_j \text{ and } a_iS^{-}a_j
	\end{cases}\\
a_iI^{(1)}a_j \Leftrightarrow a_iI^{+}a_j \text{ and } a_iI^{-}a_j\\
a_iR^{(1)}a_j \text{ otherwise}
\end{cases}
\end{equation}
where $(P^{(1)}, I^{(1)}, R^{(1)})$ represent respectively the preference, the indifference and the incomparability in PROMETHEE I.
\begin{itemize}
\item $a_iP^{(1)}a_j$ (\og $a_i$ is prefered to $a_j$ \fg): $a_i$ is simultaneously better and less worse than $a_j$.
\item $a_iI^{(1)}a_j$ (\og $a_i$ and $a_j$ are indifferent \fg): $a_i$ is neither better nor worse than $a_j$.
\item $a_iR^{(1)}a_j$ (\og $a_i$ and $a_j$ are incomparable \fg): $a_i$ is better than $a_j$ on some criteria while $a_j$ is better than $a_i$ on other criteria.
\end{itemize}

\item \textit{\underline{PROMETHEE II}}

In order to obtain a complete ranking, the net flow will be considered:
\begin{equation}
\begin{cases}
a_iP^{(2)}a_j \Leftrightarrow \phi(a_i) > \phi(a_j)\\
a_iI^{(2)}a_j \Leftrightarrow \phi(a_i) = \phi(a_j)\\
\end{cases}
\end{equation}
where $P^{(2)}$ et $I^{(2)}$ represent respectively the preference and the indifference in PROMETHEE II. This means that the higher the net flow is, the better the alternative.

Let us note that, unlike PROMETHEE I, PROMETHEE II does not suffer from incomparability and a complete ranking can directly be obtained.

\item \textit{\underline{The GAIA plane}}

While it is impossible to have a visual representation of the solution space when there are more than three criteria, the GAIA (Geometrical Analysis for Interactive Assistance) plane can give a visualization even if there are more than three criteria, by means of the computation of the net flows on the decision maker's preferences for each criterion.

The representation is based on the principal component analysis of the net flows, which allows a projection of the alternatives on a plane that minimizes the loss of information induced by this projection.
\end{enumerate}

\subsubsection{The ELECTRE methods}
ELECTRE (\textit{ELimination Et Choix Traduisant la REalitÃ©}, or ELimination and Choice Expressing REality) has been developed by Roy \cite{Roy66}. In this section, we will only described the basics of ELECTRE. More details can be found in \cite{electre}.

\begin{enumerate}
\item \textit{\underline{ELECTRE I}}

ELECTRE I is a method linked to the $P.\alpha$ problematic that aims to obtain a subset $N$ of alternatives such that all the solutions that do not belong to this set is outranked by at least one alternative of $N$. $N$ is threfore not the set of good alternatives but rather the set where the best compromise can certainly be found.

The outranking relation is obtained by establishing a weight $w_k$ for each criterion. A concordance index is the associated to each pair $(a_i, a_j)$ of alternatives:
\begin{equation}
c(a_i, a_j) = \frac{1}{W} \sum_{j:f_{k}(a_i) \geq f_{k}(a_j)}{w_{k}}, \text{ where } W = \sum_{k=1}^{m} w_{k}
\end{equation}
The concordance index represents a measure of the arguments favourable to the statement \og \textit{$a_i$ outranks $a_j$} \fg.

A discordance index can also be defined:
\begin{equation}
d(a_i, a_j) = \begin{cases}
	0& \text{if $f_{k}(a_i) \geq f_{k}(a_j), \forall k$}\\
	\frac{1}{\delta} \max_{k} [f_{k}(a_j) - f_{k}(a_i)]& \text{otherwise}
	\end{cases}
\end{equation}
The discordance index is therefore higher if the preference of $a_j$ over $a_i$ is strong on at least one criterion.

Then concordance $\hat{c}$ and discordance $\hat{d}$ thresholds are defined alongside the outranking relation $S$:
\begin{equation}
\forall i \neq j, a_iSa_j \text{ iff } \begin{cases}
	c(a_i, a_j) \geq \hat{c}\\
	d(a_i, a_j) \leq \hat{d}
	\end{cases}
\end{equation}

From this definition, a subset $N$ of alternatives is established such that:
\begin{equation}
\begin {cases}
\forall a_j \in A\setminus N, \exists a_i \in N : a_iSa_j\\
\forall a_i, a_j \in N, a_i \overline{S} a_j
\end{cases}
\end{equation}

A subset $N$ of alternatives is established such that all the alternatives that do not belong to this set is outranked by at least one alternative of $N$ and the alternatives of $N$ are incomparable. The decision process will therefore take place within the set $N$.

\item \textit{\underline{ELECTRE II}}

This method aims to rank the alternatives. The outranking relation is defined by fixing two concordance thresholds $\hat{c}_{1}$ and $\hat{c}_{2}$ such that $\hat{c}_{1} > \hat{c}_{2}$ and by building a strong outranking relation $S^{F}$ and a weak outranking relation $S^{f}$ based on these two thresholds:
\begin{equation}
a_iS^{F}a_j \text{ iff } \begin{cases}
	c(a_i, a_j) \geq \hat{c}_{1}\\
	\sum_{, : f_{k}(a_i)>f_{k}(a_j)} w_{k} > \sum_{k : g_{k}(a)<g_{k}(b)} w_{k}\\
	(f_{k}(a_i), f_{k}(a_j)) \not\in D_{k}, \forall k
	\end{cases}
\end{equation}
\begin{equation}
a_iS^{f}a_j \text{ iff } \begin{cases}
	c(a_i, a_j) \geq \hat{c}_{2}\\
	\sum_{k : f_{k}(a_i)>f_{k}(a_j)} w_{k} > \sum_{k : f_{k}(a_i)<f_{k}(a_j)} w_{k}\\
	(f_{k}(a_i), f_{k}(a_j)) \not\in D_k, \forall k
	\end{cases}
\end{equation}
The discordance can also induce two levels of relations by building two sets of discordance for each criterion.

In order to obtain the ranking, a set is determined from $S^ {F}$. This set $B$ contains the alternatives that are not strongly outranked by any others. From $B$ and $S^{f}$, the set $A^{1}$ of alternatives that are not weakly outranked by any alternatives of $B$ is determined. The set $A^{1}$ constitutes the best alternatives class. The process is repeated until a complete pre-order is obtained.

A second complete pre-order can be obtained by applying the process first with the less good alternatives class and then the best ones.

\item \textit{\underline{ELECTRE III}}

This method takes into account the indifference and preference thresholds. It is based on a valued outranking relation that is less sensible to data and parameters variabilities.

In ELECTRE III, an outranking degree $S(a_i, a_j)$ associated to each pair $(a_i, a_j)$ of alternatives is defined. It can be understood as an \og degree of credibility of outranking \fg of $a_i$ over $a_j$.

A weight $w_{k}$ is associated to each criterion and for each pair $(a_i, a_j)$ of alternatives the concordance index is computed as follows:
\begin{equation}
c(a_i, a_j) = \frac{1}{W} \sum_{k=1}^{m} w_{k} c_{k}(a_i, a_j), \text{ where } W = \sum_{k=1}^{m} w_{k}
\end{equation}
with
\begin{equation}
c_{j}(a,b) = \begin{cases}
	1& \text{if $g_{k}(a)+q_{k}(g_{k}(a)) \geq g_{k}(b)$}\\
	0& \text{if $g_{k}(a)+p_{k}(g_{k}(a)) \leq g_{k}(b)$}\\
	\text{linear in between}
	\end{cases}
\end{equation}
where $q_{k}$ et $p_{k}$ represent respectively the indifference and preference thresholds.

A ranking can be determined from a qualification index $Q(a)$ for each alternative $a$ that represents the difference between the number of outranked alternatives by $a$ and the number of alternatives that outrank $a$. A total pre-order is obtain by ranking the alternative following their qualification.

%\item \textit{\underline{ELECTRE IV}}
%
%This method is similar to ELECTRE III and aims to sort alternatives but without considering weights on the criteria.
\end{enumerate}
